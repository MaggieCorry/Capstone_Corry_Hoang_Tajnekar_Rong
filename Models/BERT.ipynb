{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59861fc3-2eda-49be-bf7a-aadbff85ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6049349-3d35-46a4-b81b-b9cdee25753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrikantwaghmare/miniconda3/envs/w266/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import sklearn as sk\n",
    "import os\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e955fc58-3d1a-460f-aa77-43c7924522b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e30082f-b83f-4330-8fd8-dc41476cae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7269 entries, 0 to 7268\n",
      "Data columns (total 9 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   project_name                    7269 non-null   object\n",
      " 1   methodology_or_protocol         7269 non-null   object\n",
      " 2   region                          7269 non-null   object\n",
      " 3   voluntary_registry              7269 non-null   object\n",
      " 4   project_type_from_the_registry  7269 non-null   object\n",
      " 5   project_developer               7269 non-null   object\n",
      " 6   arborwaproject                  7269 non-null   object\n",
      " 7   scope                           7269 non-null   object\n",
      " 8   type                            7269 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 511.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4892857-830d-4cbe-b728-ef01138b7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Value Counts:\n",
      "project_name                      7210\n",
      "methodology_or_protocol            359\n",
      "region                              13\n",
      "voluntary_registry                   4\n",
      "project_type_from_the_registry     106\n",
      "project_developer                 2572\n",
      "arborwaproject                       4\n",
      "scope                                9\n",
      "type                                78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get unique count of values in each column\n",
    "unique_counts = train_df.apply(lambda x: x.nunique())\n",
    "print(\"\\nUnique Value Counts:\")\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d25849c5-ecda-4223-a0b1-987bac7e243f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cookstoves</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wind</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Improved Forest Management</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hydropower</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afforestation/Reforestation</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Improved irrigation management</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Pneumatic Retrofit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Compost Addition to Rangeland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Grid Expansion &amp; Mini-Grids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Carbon Capture in Plastic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              type  count\n",
       "0                       Cookstoves   1166\n",
       "1                             Wind    831\n",
       "2       Improved Forest Management    597\n",
       "3                       Hydropower    419\n",
       "4      Afforestation/Reforestation    374\n",
       "..                             ...    ...\n",
       "73  Improved irrigation management      1\n",
       "74              Pneumatic Retrofit      1\n",
       "75   Compost Addition to Rangeland      1\n",
       "76     Grid Expansion & Mini-Grids      1\n",
       "77       Carbon Capture in Plastic      1\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_df = train_df[\"type\"]\n",
    "type_counts = type_df.value_counts().reset_index()\n",
    "type_counts.columns = [\"type\", 'count']\n",
    "\n",
    "type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4aff539-9993-4326-a4b0-b47dbbc2b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Shipping', 'Leak Detection & Repair in Gas Systems',\n",
      "       'Solid Waste Separation', 'Feed Additives', 'Mass Transit',\n",
      "       'University Campus Emission Reductions', 'Fleet Efficiency',\n",
      "       'Plugging Oil & Gas Wells', 'Carbon-Absorbing Concrete', 'Biochar',\n",
      "       'Bicycles', 'Carbon Capture in Concrete',\n",
      "       'Road Construction Emission Reductions',\n",
      "       'Carbon Capture & Enhanced Oil Recovery', 'Fuel Transport',\n",
      "       'Nitrogen Management', 'SF6 Replacement', 'Weatherization',\n",
      "       'N2O Destruction in Adipic Acid Production', 'Oil Recycling',\n",
      "       'Aluminum Smelters Emission Reductions', 'HFC23 Destruction',\n",
      "       'Lower Carbon Cement & Concrete',\n",
      "       'Bundled Compost Production and Soil Application', 'Waste Reduction',\n",
      "       'Refrigerant Leak Detection', 'Propylene Oxide Production',\n",
      "       'Improved irrigation management', 'Pneumatic Retrofit',\n",
      "       'Compost Addition to Rangeland', 'Grid Expansion & Mini-Grids',\n",
      "       'Carbon Capture in Plastic'],\n",
      "      dtype='object', name='type')\n",
      "(7148, 9)\n"
     ]
    }
   ],
   "source": [
    "# Projects with types lower than 10 counts\n",
    "type_counts = train_df[\"type\"].value_counts()\n",
    "\n",
    "# Identify the types with fewer than 10 counts\n",
    "types_to_drop = type_counts[type_counts < 10].index\n",
    "print(types_to_drop)\n",
    "# Drop the records with these types from train_df\n",
    "train_df_new = train_df[~train_df[\"type\"].isin(types_to_drop)]\n",
    "print(train_df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e0e1d5-967b-4524-ad24-74fe7b02d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical and Text Features\n",
    "\n",
    "categorical_features = ['region', 'voluntary_registry', 'arborwaproject']\n",
    "text_features = ['project_name','methodology_or_protocol','project_type_from_the_registry', 'project_developer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8354ccf4-f1d0-46cd-970d-c428cafde370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for concatenating text features\n",
    "def concatenate_text_features(df, text_features):\n",
    "    return [' '.join(str(row[feature]) for feature in text_features if pd.notnull(row[feature])) for _, row in df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7800c4d3-8e3d-4bcd-9649-3c6b5e3d8a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/1_m74bss7t38hngf_fsbtvlm0000gp/T/ipykernel_81736/3558406379.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df_new[\"text_features\"] = concatenate_text_features(train_df_new, text_features)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_name</th>\n",
       "      <th>methodology_or_protocol</th>\n",
       "      <th>region</th>\n",
       "      <th>voluntary_registry</th>\n",
       "      <th>project_type_from_the_registry</th>\n",
       "      <th>project_developer</th>\n",
       "      <th>arborwaproject</th>\n",
       "      <th>scope</th>\n",
       "      <th>type</th>\n",
       "      <th>text_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YESIL HYDROELECTRIC POWER PLANT (HEPP)</td>\n",
       "      <td>ACM0002</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>VCS</td>\n",
       "      <td>Energy industries (renewable/non-renewable sou...</td>\n",
       "      <td>Yeşilbas Elektrik Üretim AŞ</td>\n",
       "      <td>No</td>\n",
       "      <td>Renewable Energy</td>\n",
       "      <td>Hydropower</td>\n",
       "      <td>YESIL HYDROELECTRIC POWER PLANT (HEPP) ACM0002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS5047 VPA31 African Improved Cookstoves and C...</td>\n",
       "      <td>GS TPDDTEC v3.1</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>Energy Efficiency - Domestic</td>\n",
       "      <td>Likano Project Development GmbH</td>\n",
       "      <td>No</td>\n",
       "      <td>Household &amp; Community</td>\n",
       "      <td>Community Boreholes</td>\n",
       "      <td>GS5047 VPA31 African Improved Cookstoves and C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50 MW (DCR) Nalgonda Solar PV Power Project by...</td>\n",
       "      <td>ACM0002 Grid-connected electricity generation ...</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>Solar Thermal - Electricity</td>\n",
       "      <td>Infinite Environmental Solutions LLP</td>\n",
       "      <td>No</td>\n",
       "      <td>Renewable Energy</td>\n",
       "      <td>Solar - Centralized</td>\n",
       "      <td>50 MW (DCR) Nalgonda Solar PV Power Project by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DENIZLI WPP</td>\n",
       "      <td>ACM0002 Grid-connected electricity generation ...</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>Wind</td>\n",
       "      <td>KORDA ENERJI RETIM PAZARLAMA ITHALAT VE IHRACA...</td>\n",
       "      <td>No</td>\n",
       "      <td>Renewable Energy</td>\n",
       "      <td>Wind</td>\n",
       "      <td>DENIZLI WPP ACM0002 Grid-connected electricity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wind Based Power Generation by Rajasthan Gum P...</td>\n",
       "      <td>ACM0002</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>VCS</td>\n",
       "      <td>Energy industries (renewable/non-renewable sou...</td>\n",
       "      <td>Rajasthan Gum Private Limited</td>\n",
       "      <td>No</td>\n",
       "      <td>Renewable Energy</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Wind Based Power Generation by Rajasthan Gum P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        project_name  \\\n",
       "0             YESIL HYDROELECTRIC POWER PLANT (HEPP)   \n",
       "1  GS5047 VPA31 African Improved Cookstoves and C...   \n",
       "2  50 MW (DCR) Nalgonda Solar PV Power Project by...   \n",
       "3                                        DENIZLI WPP   \n",
       "4  Wind Based Power Generation by Rajasthan Gum P...   \n",
       "\n",
       "                             methodology_or_protocol              region  \\\n",
       "0                                            ACM0002        Western Asia   \n",
       "1                                    GS TPDDTEC v3.1  Sub-Saharan Africa   \n",
       "2  ACM0002 Grid-connected electricity generation ...       Southern Asia   \n",
       "3  ACM0002 Grid-connected electricity generation ...        Western Asia   \n",
       "4                                            ACM0002       Southern Asia   \n",
       "\n",
       "  voluntary_registry                     project_type_from_the_registry  \\\n",
       "0                VCS  Energy industries (renewable/non-renewable sou...   \n",
       "1               GOLD                       Energy Efficiency - Domestic   \n",
       "2               GOLD                        Solar Thermal - Electricity   \n",
       "3               GOLD                                               Wind   \n",
       "4                VCS  Energy industries (renewable/non-renewable sou...   \n",
       "\n",
       "                                   project_developer arborwaproject  \\\n",
       "0                        Yeşilbas Elektrik Üretim AŞ             No   \n",
       "1                    Likano Project Development GmbH             No   \n",
       "2               Infinite Environmental Solutions LLP             No   \n",
       "3  KORDA ENERJI RETIM PAZARLAMA ITHALAT VE IHRACA...             No   \n",
       "4                      Rajasthan Gum Private Limited             No   \n",
       "\n",
       "                   scope                 type  \\\n",
       "0       Renewable Energy           Hydropower   \n",
       "1  Household & Community  Community Boreholes   \n",
       "2       Renewable Energy  Solar - Centralized   \n",
       "3       Renewable Energy                 Wind   \n",
       "4       Renewable Energy                 Wind   \n",
       "\n",
       "                                       text_features  \n",
       "0  YESIL HYDROELECTRIC POWER PLANT (HEPP) ACM0002...  \n",
       "1  GS5047 VPA31 African Improved Cookstoves and C...  \n",
       "2  50 MW (DCR) Nalgonda Solar PV Power Project by...  \n",
       "3  DENIZLI WPP ACM0002 Grid-connected electricity...  \n",
       "4  Wind Based Power Generation by Rajasthan Gum P...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"text_features\"] = concatenate_text_features(train_df_new, text_features)\n",
    "train_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff437ec-f02f-4baa-84cc-6b3c84662364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6433, 9) (715, 9) (6433,) (715,)\n"
     ]
    }
   ],
   "source": [
    "## Splitting the train to train and validation sets\n",
    "X_train_df = train_df_new.drop(columns=['type'])\n",
    "Y_train_df = train_df_new['type']\n",
    "X_train, X_val, Y_train, Y_val  = train_test_split(X_train_df,Y_train_df, test_size=0.1, stratify =Y_train_df,  random_state=42)\n",
    "print(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0521c9d8-2878-487e-910c-e86ea39f2431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45  8 19 19 11]\n"
     ]
    }
   ],
   "source": [
    "# Function to encode labels, handling unseen labels with a default category\n",
    "def encode_labels(label_encoder, labels):\n",
    "    encoded_labels = []\n",
    "    for label in labels:\n",
    "        if label in label_encoder.classes_:\n",
    "            encoded_labels.append(label_encoder.transform([label])[0])\n",
    "        else:\n",
    "            encoded_labels.append(len(label_encoder.classes_))  # Example: len(label_encoder.classes_) represents the default category\n",
    "    return encoded_labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(Y_train)\n",
    "Y_train_encoded = np.asarray(encode_labels(label_encoder, Y_train))\n",
    "Y_val_encoded = np.asarray(encode_labels(label_encoder, Y_val))\n",
    "\n",
    "print(Y_train_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c74407-a684-4a70-b016-8575f5796e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class F5Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f5_score', **kwargs):\n",
    "        super(F5Score, self).__init__(name=name, **kwargs)\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.argmax(y_pred, axis=1)\n",
    "        \n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "\n",
    "        tp = tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n",
    "        fp = tf.reduce_sum(tf.cast(tf.not_equal(y_true, y_pred), tf.float32))\n",
    "        fn = tf.reduce_sum(tf.cast(tf.not_equal(y_pred, y_true), tf.float32))\n",
    "\n",
    "        self.tp.assign_add(tp)\n",
    "        self.fp.assign_add(fp)\n",
    "        self.fn.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "        return 5 * (precision * recall) / (4 * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a2364-d54a-44d5-a765-fb03be9b86e6",
   "metadata": {},
   "source": [
    "### Classification with a fine tuned BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbdf464a-3a26-4876-ad39-53fee66a60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e83c9e5-9086-43ac-9b23-87c01c7da217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it easier to use a variety of BERT subword models\n",
    "model_checkpoint = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea8ae83d-c742-44ff-b439-c22e47e9a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
    "bert_model = TFBertModel.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ab377-10d4-4a0a-b43b-6a0de85d3184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af7c56a-8d05-4779-8478-8b61182fa246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the dataset, truncate at `max_length`,\n",
    "# and pad with 0's when less than `max_length` and return a tf Tensor\n",
    "max_length = 200\n",
    "X_train_text_features = X_train[\"text_features\"].astype(str).tolist()\n",
    "Y_train_text_features = X_val[\"text_features\"].astype(str).tolist()\n",
    "train_encodings = bert_tokenizer(X_train_text_features, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors='tf')\n",
    "valid_encodings = bert_tokenizer(Y_train_text_features, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b86865c1-77c5-49fa-b635-f85fb2011a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200), dtype=int32, numpy=\n",
       "array([[  101, 23396, 26978, 26580,  1513,  5514,  9690,  2107,  7629,\n",
       "         1568,  1477,  5514,  7519,   113, 17216,   120,  1664,   118,\n",
       "        17216,  3509,   114,  4149,  1389,  2599,   144,  5970,  2599,\n",
       "         1186,  1260, 13832,  1200,  9037,   156,   119,   138,   119,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.input_ids[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76afff34-de33-42e4-96ea-c7356dfba0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6433, 200)\n",
      "(715, 200)\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings.input_ids.shape)\n",
    "print(valid_encodings.input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "126e6632-9e8e-4428-815f-1a2d9194cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_multiclass_model(checkpoint = model_checkpoint,\n",
    "                                 num_classes = 20,\n",
    "                                 hidden_size = 201,\n",
    "                                 dropout=0.3,\n",
    "                                 learning_rate=0.00005):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Use the Pooler Output for classification purposes.\n",
    "    \"\"\"\n",
    "    bert_model = TFBertModel.from_pretrained(checkpoint)\n",
    "    #bert_model.trainable = True\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}\n",
    "\n",
    "    bert_out = bert_model(bert_inputs)\n",
    "\n",
    "    pooler_token = bert_out[1]\n",
    "\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooler_token)\n",
    "\n",
    "    hidden = tf.keras.layers.Dropout(dropout)(hidden)\n",
    "\n",
    "    classification = tf.keras.layers.Dense(num_classes, activation='softmax',name='classification_layer')(hidden)\n",
    "\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "\n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                 loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                                 metrics=['accuracy'])\n",
    "\n",
    "    classification_model.summary()\n",
    "    ### END YOUR CODE\n",
    "    return classification_model\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38648851-0e2e-42a2-aa0d-c4fed9aa15c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask_layer (InputLay  [(None, 200)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " input_ids_layer (InputLayer)   [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids_layer (InputLay  [(None, 200)]       0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  108310272   ['attention_mask_layer[0][0]',   \n",
      "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids_layer[0][0]']   \n",
      "                                n_state=(None, 200,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 201)          154569      ['tf_bert_model_1[0][1]']        \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 201)          0           ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 46)           9292        ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,474,133\n",
      "Trainable params: 108,474,133\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pooler_bert_model = create_bert_multiclass_model(checkpoint=model_checkpoint,\n",
    "                                                 num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec7e99ab-1f04-4e2e-ab8d-f9297c0395e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6433,)\n",
      "(715,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_encoded.shape)\n",
    "print(Y_val_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9146801-bfdf-4b3c-aed4-233e915f5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 19:46:00.818974: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 6103s 30s/step - loss: 1.4230 - accuracy: 0.6653 - val_loss: 0.5179 - val_accuracy: 0.8615\n"
     ]
    }
   ],
   "source": [
    "pooler_bert_model_history = pooler_bert_model.fit(\n",
    "    [train_encodings.input_ids, train_encodings.token_type_ids, train_encodings.attention_mask],\n",
    "    Y_train_encoded,\n",
    "    validation_data=([valid_encodings.input_ids, valid_encodings.token_type_ids, valid_encodings.attention_mask], Y_val_encoded),\n",
    "    batch_size=32,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d456ced-bc43-4487-acda-23112dfbc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler_bert_model.save(\"../data/models/bert_acc_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5158a-f7e8-4a46-be9e-875a3dca6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pooler_bert_model.evaluate([valid_encodings.input_ids, valid_encodings.token_type_ids, valid_encodings.attention_mask],\n",
    "                                                  Y_val_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1059d8d3-bc7e-4a88-8c8a-1106827b4465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5179084539413452\n",
      "Val accuracy: 0.8615384697914124\n"
     ]
    }
   ],
   "source": [
    "print('Val loss:', score[0])\n",
    "print('Val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8126618-5a86-4192-81bf-0efbb0bc16ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
